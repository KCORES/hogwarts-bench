# Hogwarts-bench Configuration Example
# Copy this file to .env and fill in your values

# ============================================================================
# LLM Configuration
# ============================================================================

# OpenAI API Key (required)
# Get your API key from OpenAI or your API provider
OPENAI_API_KEY=your_api_key_here

# OpenAI Base URL (optional)
# Default: https://openrouter.ai/api/v1
# For OpenAI: https://api.openai.com/v1
# For other providers: use their API endpoint
OPENAI_BASE_URL=https://openrouter.ai/api/v1

# Model Name (required)
# Examples:
#   - OpenRouter: anthropic/claude-3-sonnet, openai/gpt-4-turbo
#   - OpenAI: gpt-4-turbo-preview, gpt-3.5-turbo
MODEL_NAME=anthropic/claude-3-sonnet

# ============================================================================
# Generation Settings
# ============================================================================

# Temperature for LLM generation (0.0 - 2.0)
# Lower values make output more deterministic
# Default: 0.7
DEFAULT_TEMPERATURE=0.7

# Maximum tokens in LLM response
# Default: 2000
DEFAULT_MAX_TOKENS=2000

# Request timeout in seconds
# Default: 60
DEFAULT_TIMEOUT=60

# ============================================================================
# Concurrency Settings
# ============================================================================

# Default number of concurrent API requests
# Adjust based on your API rate limits
# Default: 5
DEFAULT_CONCURRENCY=5

# Default number of retry attempts for failed requests
# Default: 3
DEFAULT_RETRY_TIMES=3

# ============================================================================
# Optional: Advanced Settings
# ============================================================================

# Tokenizer encoding name
# Default: cl100k_base (used by GPT-4 and GPT-3.5-turbo)
# TOKENIZER_ENCODING=cl100k_base

# Log level (DEBUG, INFO, WARNING, ERROR)
# LOG_LEVEL=INFO
